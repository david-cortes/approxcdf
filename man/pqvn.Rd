% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/approxcdf.R
\name{pqvn}
\alias{pqvn}
\title{Cumulative Distribution Function for Quadrivariate Normal Distribution}
\usage{
pqvn(q, Rho, prefer_original = FALSE)
}
\arguments{
\item{q}{A 4-dimensional vector with the thresholds/upper bounds for the variables for which the CDF
will be calculated.}

\item{Rho}{The correlation matrix parameterizing the distribution.}

\item{prefer_original}{Whether to prefer Plackett's original reduction form (reference matrix number
7 in Gassmann's classification) regardless of the determinant.}
}
\value{
The CDF calculated through Plackett's recursive reduction for the quadrivariate normal
distribution and thresholds provided here.
}
\description{
Calculates the CDF (cumulative distribution function) of a
4D/quadrivariate standardized normal distribution using Plackett's or Plackett-Gassmann's
reduction, aided by the more exact 3D and 2D CDF methods from Genz (adapted from the TVPACK
library) for lower-dimensional subproblems.

In general, this method is both slower and less precise than Bhat's method as used by \link{pmvn},
and is provided for experimentation purposes only.
}
\details{
The implementation here differs from Gassmann's paper in a few ways:
\itemize{
\item It prefers the reference matrix number 2 in Gassmann's classification, unless some
correlation coefficients are zero or one, in which case it will prefer matrix number 5
(which was Gassmann's recommendation).
\item If the determinant of the correlation matrix is very low, it will prefer instead
Gassmann's matrix number 7 (Plackett's original choice).
\item When using reference matrices 2 or 5, it will make the probability corrections
in a recursive fashion, zeroing out one correlation coefficient at a time, instead of making
corrections for all correlations in aggregate. From some experiments, this turned out to result
in slower but more accurate calculations when correcting for multiple correlations.
\item If the determinant of a given correlation matrix is high enough, it will use the
Woodbury matrix identity when calculating gradients for corrections, which is faster but
less accurate.
\item The number of Gaussian-Legendre points used here is higher than in Plackett's, but
lower than in Gassmann's.
}

Although Gassmann's paper suggested that this method should have a maximum error of \eqn{5 \times 10^{-5}}
in a suite of typical test problems, some testing with random matrices (typically not representative
of problems of interest due to their structure) shows that the average error to expect is around
\eqn{10^{-3}} and the maximum error can be as bad as \eqn{10^{-1}}.

Note that this function will not perform any validation of the data that is passed - it is
the user's responsibility to ensure that the provided arguments are correct.
}
\examples{
library(approxcdf)

### Example from Plackett's paper
b <- c(0, 0, 0, 0)
S <- matrix(
c( 1,  -0.60,  0.85,  0.75,
-0.60,    1,  -0.70, -0.80,
 0.85, -0.70,    1,   0.65,
 0.75, -0.80,  0.65,    1),
nrow=4, ncol=4, byrow=TRUE)

### Solution using Plackett's original reduction
pqvn(b, S, prefer_original=TRUE)
### (Plackett's estimate was 0.042323)
}
\references{
\itemize{
\item Plackett, Robin L. "A reduction formula for normal multivariate integrals." Biometrika 41.3/4 (1954): 351-360.
\item Gassmann, H. I.
"Multivariate normal probabilities: implementing an old idea of Plackett's."
Journal of Computational and Graphical Statistics 12.3 (2003): 731-752.
\item Genz, Alan.
"Numerical computation of rectangular bivariate and trivariate normal and t probabilities."
Statistics and Computing 14.3 (2004): 251-260.
}
}
